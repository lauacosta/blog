---
 {"title":"What Does Type Safety Mean","private": true} 
---

# What Does Type Safety Mean

Have you ever doubted yourself when trying to explain what _type safety_ is? Maybe you read it in a blog post somewhere on social media where programmers were fighting on behalf of their [blessed](https://blog.aurynn.com/2015/12/16-contempt-culture/) language, or in an announcement for the latest Typescript library, but you were never sure you _knew_ what it meant? 

It has happened to me. So I made an effort to try to explain to myself what it meant, hopefully it works for you too! The article touches _many_ concepts but I try to keep it grounded and add examples where I feel they help to illustrate a concept better for someone like me.
{% But, wait. What even _is_ a type? [Glad you ask](/what_is_a_type.html) %}

## Sound languages

I found two popular definitions for what a safe language is. The first is from _"[The Practical Foundations of Programming Languages](https://www.cs.cmu.edu/~rwh/pfpl.html)"_ book by Robert Harper:

> Most programming languages exhibit a phase distinction between the static and dynamic phases of processing. The static phase consists of parsing and type checking to ensure that the program is well-formed; the dynamic phase consists of execution of well-formed programs. A language is said to be safe exactly when well-formed programs are well-behaved when executed.
>
> The static phase is specified by a statics comprising a collection of rules for deriving typing judgments stating that an expression is well-formed of a certain type. Types mediate the interaction between the constituent parts of a program by “predicting” some aspects of the execution behavior of the parts so that we may ensure they fit together properly at run-time. Type safety tells us that these predictions are accurate; if not, the statics is considered to be improperly defined, and the language is deemed unsafe for execution.

This tells us that the _statics_ uses typing judgments to verify that the program satisfies the constraints encoded in the type system. While the realm of how a program is evaluated belongs to the _dynamics_.

Harper highlights a key _use_ for types: they predict aspects of the execution to ensure they will fit together at runtime.

It also introduces the concept of a well-formed program: one that has passed parsing and type checking. We'll refer to them as _well-typed_ programs, otherwise they are _ill-typed_ which means that they are _ill-behaved_ or can't be proven to be _well-behaved_.

Harper defines a language as _safe_ if _all_ well-typed programs are well-behaved: meaning they exhibit only behaviors predicted by the statics. This property is called type soundness: the statics are _sound_ with respect to the dynamics.

Therefore, a language may be described as either "safe/sound" or "unsafe/unsound" relative to the relationship between the statics and the dynamics. We'll use them interchangeably throughout the article, unless explicitly said otherwise.

The _"[Type Systems](https://courses.grainger.illinois.edu/cs421/fa2018/CS421A/resources/cardelli.pdf)"_ paper by Luca Cardelli says something similar:

> It is useful to distinguish between two kinds of execution errors: the ones that cause the computation to stop immediately, and the ones that go unnoticed (for a while) and later cause arbitrary behavior. The former are called trapped errors, whereas the latter are untrapped errors.
>
> …
>
> A program fragment is safe if it does not cause untrapped errors to occur. Languages where all program fragments are safe are called safe languages. 

This definition is, in a way, more permissive. In the paper, Cardelli classifies division by zero as a trapped error since many architectures catch it. However, I argue that a _language_ shouldn't be deemed safe because the architecture the _program_ happens to execute on catches certain kinds of errors. Later we'll explore a case study that illustrates this.

 ****

Remember I said we'll look at the role of a _type system_? Well, now is the time. Let's look at some acceptions.

Harper states that the role of a type system is:

> The role of a type system is to impose constraints on the formations of phrases that are sensitive to the context in which they occur.

[Mmmhmm](https://youtu.be/oK3yTGtxOPY?t=35), it makes sense but it does not tell me much. I get what he is trying to say but I think we can find a more practical definition.

Cardelli says:

> The primary goal of a type system is to ensure language safety by ruling out all untrapped errors in all program runs. However, most type systems are designed to ensure the more general good behavior property, and implicitly safety. Thus, the declared goal of a type system is usually to ensure good behavior of all programs, by distinguishing between well typed and ill typed programs.

To showcase what this means, imagine this function defined in a fictitious language which has the property of being sound, meaning that well-typed programs are well-behaved at runtime.

``` rust
fn add(a: Int, b: Int) Int {
    return a + b;
}

// This would result in a well-typed program.
let res = add(10, 314);

// This would result in an ill-typed program.
let res = add(10, "Some");
``` 

The expression `add(10, 314)` _is_ sensible because `add` requires its arguments to be of type `Int` and both `10` and `314` satisfy this requirement; therefore the program is well-typed. Because the statics for `Int` would guarantee that the `+` operator will not get _stuck_ and as a result the program lies within the guarantees of the language.

By comparison, `add(10, "Some")` is ill-typed because `"Some"` does not have type `Int` so it doesn't satisfy the context and allowing it to execute would violate the guarantees of the language. To further clarify this:

``` rust
fn add(a: Int, b: Str) Int {
    return a + b;
}

let res = add(10, "Some");
```
The program may or may not be well-typed depending on the statics of the language.

- There is a rule defined for `+` given `Int` and `Str`, the program is well-typed and guaranteed not to get stuck.
- No rule exists; the program is ill-typed and executing it would break the language guarantees (the statics).

Now, to showcase when a language is unsound, let's first drop the assumption that the language we are using is sound and take a look at this example:

``` rust
fn div(a: Int, b: Int) : Int {
    return a / b
}

let res = div(10, 0);
```

This program is clearly well-typed, but stating that the language is safe depends on the dynamics. We can decide according to how they handle the division by zero:

- The dynamics do not define what happens in this failure case, undefined behavior creeps in, making the language unsound.
- If Division by zero as a behavior is accounted for in the dynamics of the language, then the language is considered sound. This could be handled by static or dynamic checks (dynamic checks being the easiest to implement; these are mechanisms such as throwing errors, exceptions, panicking, returning a special value, etc.).

## Case study

Now let's look at how two real languages handle the same error case. One in Rust and the other in C:

``` rust
fn div(a: u32, b: u32) -> u32 {
    a / b
}

fn main() {
    let res = div(10, 0);
    println!("{res}");
}
```

Results in a panic:

```bash 
$ rustc -o main main.rs; ./main

thread 'main' (432991) panicked at main.rs:2:5:
attempt to divide by zero
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace
with a full backtrace in:
```

If we add the `RUST_BACKTRACE=1` env variable we can see the language's built-in error handling machinery at work:

{highlight=10}
``` bash
$ rustc -o main main.rs; RUST_BACKTRACE=1 ./main

thread 'main' (433803) panicked at main.rs:2:5:
attempt to divide by zero
stack backtrace:
   0: __rustc::rust_begin_unwind
             at /rustc/2286e5d224b3413484cf4f398a9f078487e7b49d/library/std/src/panicking.rs:690:5
   1: core::panicking::panic_fmt
             at /rustc/2286e5d224b3413484cf4f398a9f078487e7b49d/library/core/src/panicking.rs:80:14
   2: core::panicking::panic_const::panic_const_div_by_zero
             at /rustc/2286e5d224b3413484cf4f398a9f078487e7b49d/library/core/src/panicking.rs:175:17
   3: main::div
   4: main::main
   5: core::ops::function::FnOnce::call_once
```

Rust does not yet have a formal specification; the closest thing is the [Rust Reference](https://doc.rust-lang.org/reference/), and in there we can see that this behavior is [*defined by the language*](https://doc.rust-lang.org/nightly/reference/expressions/operator-expr.html?highlight=division#arithmetic-and-logical-binary-operators:~:text=%E2%80%A0%20For%20integer%20types%2C%20division%20by%20zero%20panics): division by zero does not result in undefined behavior, but instead transitions the program to a specified error state where computation is stopped immediately. Even though the program ends abruptly, it doesn't reach an undefined state, panicking is a defined outcome. This is why Rust remains sound in the presence of such an error.

::: info
Recovering from a panic like this can be done by using [`catch_unwind`](https://doc.rust-lang.org/std/panic/fn.catch_unwind.html), but that is the wrong tool for expected failures. Instead, one should favor more idiomatic approaches, such as [`checked_div`](https://doc.rust-lang.org/std/primitive.u32.html#method.checked_div), which returns an `Option` instead of panicking, or encoding the [invariants](https://matklad.github.io/2023/10/06/what-is-an-invariant.html) in the function's type signature.
:::

Now on the C program:

``` c
#include <stdio.h>

int div(int a, int b) {
    return a / b;
}

int main() {
    int res = div(10,0);
    printf("%d", res);
}
```

The program successfully compiles, so it is considered to be well-typed by this implementation of the C language, but when executed:

``` bash
$ gcc -g -O0 -o main main.c && ./main
Floating point exception   (core dumped) ./main
```

We can use `gdb` to see a backtrace of what happened:

{highlight="4,7,14"}
```bash
$ gcc -g -O0 -o main main.c && gdb -q ./main -ex run \ 
-ex "set disassembly-flavor intel" -ex disassemble -ex quit
...
Program received signal SIGFPE, Arithmetic exception.
0x0000555555555147 in div (a=10, b=0) at main.c:4
4           return a / b;
Dump of assembler code for function div:
   0x0000555555555139 <+0>:     push   rbp
   0x000055555555513a <+1>:     mov    rbp,rsp
   0x000055555555513d <+4>:     mov    DWORD PTR [rbp-0x4],edi
   0x0000555555555140 <+7>:     mov    DWORD PTR [rbp-0x8],esi
   0x0000555555555143 <+10>:    mov    eax,DWORD PTR [rbp-0x4]
   0x0000555555555146 <+13>:    cdq
=> 0x0000555555555147 <+14>:    idiv   DWORD PTR [rbp-0x8]
   0x000055555555514a <+17>:    pop    rbp
   0x000055555555514b <+18>:    ret
End of assembler dump.
```

Now we can see that the fault came from our `div` function. Check how at address `0x0000555555555147` the division is performed with the `idiv` instruction on x86_64. Since the divisor is zero, the CPU raises a `#DE` (Division Error) exception. The OS handles it by sending a `SIGFPE` signal to the program. 

The latest publicly available [C language specification](https://www.open-std.org/jtc1/sc22/wg14/www/docs/n1570.pdf#page=110) classifies this as undefined behavior (UB). This results in a greenfield for compiler optimizations since they take full advantage on the fact that the C _abstract model_ states this is an undefined state. Whether the program crashes, hangs, or produces unpredictable results depends on compiler optimizations and the target architecture and OS. This illustrates one way C's type system is unsound: even well-typed programs can reach runtime states that the language does not account for.

To showcase what can happen if we allow optimizations, let's enable them in both [`gcc`](https://gcc.gnu.org/) and [`clang`](https://clang.llvm.org/):

{highlight="4, 8"}
```bash
$ gcc -g -O3 -o main main.c && gdb -q ./main -ex run \
-ex "set disassembly-flavor intel" -ex disassemble -ex quit
...
Program received signal SIGILL, Illegal instruction.
main () at main.c:8
8           int res = div(10,0);
Dump of assembler code for function main:
=> 0x0000555555555020 <+0>:     ud2
End of assembler dump.
```

Notice how the fault came directly from our `main` function. Inspecting the assembly we see that the compiler optimized the whole program to a `ud2` instruction which generates a `#UD` (Invalid Opcode) exception. Now the program receives a `SIGILL` from the OS.

{highlight="2, 11"}
```bash
$ clang -O3 -o main main.c && ./main 
151705912 

$ clang -O3 -o main main.c && gdb -q ./main -ex "set disassembly-flavor intel" \
-ex "disassemble main" -ex quit
...
Dump of assembler code for function main:
   0x0000000000001150 <+0>:     push   rax
   0x0000000000001151 <+1>:     lea    rdi,[rip+0xeac]        # 0x2004
   0x0000000000001158 <+8>:     xor    eax,eax
   0x000000000000115a <+10>:    call   0x1030 <printf@plt>
   0x000000000000115f <+15>:    xor    eax,eax
   0x0000000000001161 <+17>:    pop    rcx
   0x0000000000001162 <+18>:    ret
End of assembler dump.
```

This is interesting: without optimizations it behaves similarly to the GCC-compiled one. With optimizations enabled, Clang also deletes `div`; however, it doesn't replace main's body with a `ud2` and instead continues execution normally, printing an arbitrary value!

This is why I don't agree with the definition of a safe language that Cardelli gave. In Rust, division by zero is handled _by the language_, making both the program and the language sound. In C with optimizations disabled, turns out this particular program _is_ safe in practice and matches what Cardelli says since it doesn't have untrapped errors. 

My point is that it doesn't make the _language_ safe. It is considered a trapped error because the OS caught a hardware-exception, _not_ because the language defined it as so [^UBSan]. We can see that if we allow optimizations this accidental safety can even dissapear!

It's important to repeat what I said above about well-typed programs reaching undefined states. That clearly violates the framework Harper promotes. For him, the C program would _never_ be considered safe because the behavior is not specified in the language, even when it happens to be safe in practice.

## What is type safety 

Now we can define that _Type Safety_ expresses the coherence between the statics and the dynamics; where the statics are seen as predicting that the value of an expression will have a certain form so that the dynamics of that expression is well-defined. We'll refer to type safety and soundness interchangeably.

Consequently, evaluation of a well-typed expression cannot _get_ stuck! It can never reach a non-value state for which no evaluation rule applies. This can be achieved by proving two theorems named _Preservation_ and _Progress_.

### Preservation and progress

Let's first introduce some notation to express these theorems precisely:

```bash
'Γ'     the static environment or typing context. 
'⊢'     the turnstile; reads as "under the assumption of".
'τ'     the type in question.
':'     the typing relation.
'->'    single step evaluation.
'∧'     is logical "and".
'∅'     the empty typing context.
'∃'     existential quantifier.
'∨'     is logical "or".
'val'   denotes that e is a value.
'.'     the binder operator and reads as “such that”.
```
Where Γ represents all the variables that are in the scope alongside their types. It's used in the relation Γ ⊢ e : τ that can be read as "the typing context _shows_ that `e` has type τ".

Now, the theorems can be expressed as:

```bash
1. If Γ ⊢ e : τ ∧ e -> e', then Γ ⊢ e': τ       # Preservation
2. If ∅ ⊢ e : τ then (e val) ∨ (∃ e'. e -> e')  # Progress
```

The first theorem is called _Preservation_ and it can be read as _"if under the typing context Γ, e has type τ and e steps to e' in one step, then e' also has type τ under Γ"_. It ensures that the steps of evaluation preserve typing.

 The second is called _Progress_ and it can be read as _"if under the empty typing context ∅, e has type τ then e is either a value or there exists a expression e' reachable by a single step from e"_. It ensures that well-typed closed expressions are either values or can be further evaluated. As you could have guessed by now, a term is "stuck" when it fails to satisfy these conditions.

_Safety is the conjunction of Preservation and Progress_.

Now that we have these tools, we can revisit the C example and see that the type system is considered _unsound_ because, while it is well-typed, during evaluation it reaches a configuration for which no evaluation rule applies (it violates _Progress_).

## Where do dynamic languages fit?

After all of this, you may be left wondering what's the case for languages like Javascript or Python, the so-called _dynamic languages_.

Fortunately, Harper can help. He argues that the distinction between static and dynamic languages is illusory; instead, dynamic languages embrace a model of computation where multiple _classes_ of values exist for a *single recursive type*.

> Every dynamic language is inherently a static language in which we confine ourselves to a (needlessly) restricted type discipline to ensure safety.

The trick of it is on understanding what he calls "type discipline"; turns out that in this type of languages, every value is _tagged_ to indicate which _class_ of value they belong through a process called _Classification_. Since the static phase limits itself to only check that the expression is well-formed[^dynamic-well-formed] and that there are _no free variables_ in the expression; the dynamics _must_ check for errors during runtime that would have never arisen in a statically-typed language; this is called _Class Checking_ and uses the tags each value is forced to have. This is what Harper refers to as "type discipline".

[^dynamic-well-formed]: Here "well-formed" stands for parsing not type-checking.

To illustrate the concepts, it's useful to look at an example in the wild. A case of this single recursive type we mentioned earlier can be found in the [CPython Language Reference](https://docs.python.org/3/). It defines a type [`PyObject`](https://docs.python.org/3/c-api/structures.html#c.PyObject), where *all object types are extensions of this type* and one of its fields, called `ob_type`, is a pointer to [`PyTypeObject`](https://docs.python.org/3/c-api/type.html#c.PyTypeObject) and encodes _the object type_ which is exactly the idea of tagging a value to know to which class of value they belong to.

Now that we have introduced all of this. What happens to the theorems of Preservation and Progress? How do we talk about type safety in these kinds of language? 

Harper presents the theorem of _Progress_ as:

``` bash
If d ok, then (d val) ∨ (d err) ∨ (∃ d' . d->d')
```

This reads as "If `d` is a closed expression, then it's either a value, results in a runtime error or it can be further evaluated". He also defines _Exclusivity_, which states that, for any `d` in the language, _exactly one_ of these outcomes must be true at any given time.

The key difference is that, in the previous model, these kinds of errors were guaranteed to not occur for well-typed programs. But, since catching those before evaluation requires a static language, now they have become part of the semantics of the language! This way, evaluation never becomes _stuck_. I think it's relevant to notice how now catching these errors falls upon the dynamics of the language, adding a non-negligible overhead.

And since there exists only one singular recursive type, _Preservation_ plays a lesser role here; there is no static type information to preserve between evaluations! The runtime, through _Classification_ and _Class Checking_, enforces the discipline that guarantees safe evaluation. 

::: info
There have been efforts towards introducing static typing to dynamic languages. In Python there are external tools like [mypy](https://mypy-lang.org/) and [ty](https://docs.astral.sh/ty/) for performing static analysis on annotations. [Typescript](https://www.typescriptlang.org/) plays a similar role by adding a static type system whose types are erased when compiling to Javascript. More recently [Elixir](https://hexdocs.pm/elixir/main/gradual-set-theoretic-types.html) has been working on adding a [gradual type system](https://drops.dagstuhl.de/storage/00lipics/lipics-vol032-snapl2015/LIPIcs.SNAPL.2015.274/LIPIcs.SNAPL.2015.274.pdf) to the language itself.
:::

## A note on soundness

At last, we enter the final section of the article. It's been a long journey to write and I bet it was to read too.

We have discussed what soundness is and what it is there for: it makes programs written in languages that have it easier to reason about and helps avoid whole classes of bugs and foot-guns. 

However, I want to express some opinions I have been saving in order to not muddle the explanations of the sections before.

From what I read, both Harper and Cardelli seem to heavily focus on the _abstract semantics_ of the languages to determine if they are sound or not which could very well make sense for the work they do. In contrast, I am but a humble programmer; I read these criteria and find them _somewhat_ useful. I hinted at this in the conclusion of the case study; I find these definitions not enough for defining if a program is safe for execution or not. Maybe it makes sense, since soundness is a _property_ of the abstract semantics of the language.

It is so that if we took C and changed its specification so every case of UB transitioned to an error state, or we defined UB as as belonging to the set of "trapped errors", under the frameworks we saw, the program we wrote earlier would be considered safe; yet, nothing about the actual execution would have changed! Merely changing that doesn't immediately affect the optimizations the compiler could have done nor does it erase the danger UB represents. 

This tells me that soundness, as a property of a language, doesn't automatically translate into practical safety guarantees. Matklad has a nice article that talks more about this and that deals with a term often seen alongside type safety, [memory safety](https://matklad.github.io/2025/12/30/memory-safety-is.html).

Note that now I am broadening the discussion beyond soundness. I would _always_ want to know if a program I run is safe, not _only_ in the sense of soundness. To do so I can't ignore  how the _implementation_ of a language that has to run on a _concrete_ machine affects the practical safety guarantees the users of the language experience. 

Now, remember that it's totally possible to write programs, that are sound in practice, in unsound languages by restricting oneself to use only the sound subset of the language. In fact, it may happen that within the space of all possible programs written in the language, the unsound features are never encountered in practice! It is possible too, to write seemingly unsafe programs that turn out  to be safe in practice due to the infrastructure where they run.

This obviously moves the bulk of the work that could be done by proper semantics and a type system to the user since they will have to rely on their own experience and the maturity of the community to learn the [patterns](https://www.lysator.liu.se/c/ten-commandments.html) to navigate these waters.

Also, history clearly tells us that soundness is not by itself indicative of a language's usefulness. Many widely used languages have had unsound type systems for decades yet programmers continue writing critical software with them (just think about all the software written in [C](https://blog.regehr.org/archives/213) and [Java](https://dl.acm.org/doi/10.1145/2983990.2984004)). 

Languages can be unsound _by design_, trading soundness for goals like:

- Squeezing max performance by allowing optimizations (C or C++)
- A simpler type system ([Go](https://fasterthanli.me/articles/lies-we-tell-ourselves-to-keep-using-golang))
- Prioritize compatibility and ease of adoption (Typescript)

In mainstream languages, known cases of unsoundness are generally well-documented ([C++](https://en.cppreference.com/w/c/language/behavior.html) or [Rust](https://doc.rust-lang.org/reference/behavior-considered-undefined.html), for example). Unknown unsoundness, by contrast, could cause correctness and security problems or [allow time travel](https://devblogs.microsoft.com/oldnewthing/20140627-00/?p=633).

Even though I appreciate working with a sound type system, I don't believe having an unsound type system makes a language worse or disqualifies it for use; after all, *languages are tools*, and their usefulness is primarily dictated by the context in which they are used.


[^UBSan]: One can pass `-sanitize=undefined` to `gcc` or `clang` to catch the error at runtime but that is achieved using [UBSan](https://docs.kernel.org/dev-tools/ubsan.html) which is not something defined in the language.
